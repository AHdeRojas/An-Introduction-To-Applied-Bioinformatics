{
 "metadata": {
  "name": "5-file-io"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**File I/O**\n",
      "\n",
      "Today we'll learn how to interact with files, including how to read from them and write to them. We'll also cover some tips for parising files."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First, to open files we use the built in ``open`` function, which takes a file path and a `mode` to open the file in. The commonly used modes are ``U`` (read, with universal line break support), ``r`` (read, with unix line break support), ``w`` (write, overwriting any existing file content), and ``a`` (write, appending to any existing file content).\n",
      "\n",
      "We'll define the path to an existing file first. You can run some of the common shell commands to see what the file looks like (remember that prefixing a line with ``!`` means that it should be run with ``python`` instead of ``bash``."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fp = \"glen_canyon_map.tsv\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ls $fp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "glen_canyon_map.tsv"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!head $fp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "#SampleID\tBarcodeSequence\tsite_number\tbag_sample_id\tsample_pH\tSample_Type\tWell_ID\tSample_Plate\tPrimer_Plate\tLane\tLatitude\tLongitude\tType\tEnv\tSourceSink\testimated_elevation\tCurrentlyWet\testimated_years_since_submerged\testimated_years_since_submerged_for_plotting\testimated_last_submerged\tgps_elevation\tgps_elevation_minus_estimated_elevation\tMonth\tDay\tYear\tdays_since_epoch\tHour\tSite\tSite_Name\tReplicate\tDNA.I.D.No.\tDescription\n",
        "Halls10R1\tTACGCGCTGAGA\t10\tha10r1\t9.52\tSoil\tg1\tGlenCanyon\t5\tLane4\tno_data\tno_data\tSoil\tLocalSoilCrust\tsource\t3723\tNo\tNA\t37\tNA\t3740\t17\t9\t29\t2010\t14881\t12\tHalls10\tHalls\t1\t11\tGlenCanyon_ha10r1\n",
        "Halls10R2\tTAGATCCTCGAT\t10\tha10r2\t9.5\tSoil\th1\tGlenCanyon\t5\tLane4\tno_data\tno_data\tSoil\tLocalSoilCrust\tsource\t3723\tNo\tNA\t37\tNA\t3740\t17\t9\t29\t2010\t14881\t12\tHalls10\tHalls\t2\t12\tGlenCanyon_ha10r2\n",
        "HCanyon10R1\tGCTTGCGAGACA\t10\thc9r1\t9.29\tSoil\ta5\tGlenCanyon\t5\tLane4\tN37_33.006\tW110_40.590\tSoil\tLocalSoilCrust\tsource\t3723\tNo\tNA\t37\tNA\t3732\t9\t9\t30\t2010\t14882\t1\tHCanyon10\tHcanyon\t1\t43\tGlenCanyon_hc9r1\n",
        "HCanyon10R2\tGTACGGCATACG\t10\thc9r2\t9.25\tSoil\tb5\tGlenCanyon\t5\tLane4\tN37_33.006\tW110_40.590\tSoil\tLocalSoilCrust\tsource\t3723\tNo\tNA\t37\tNA\t3732\t9\t9\t30\t2010\t14882\t1\tHCanyon10\tHcanyon\t2\t44\tGlenCanyon_hc9r2\n",
        "HCanyon10R3\tGTATGCGCTGTA\t10\thc9r3\t9.23\tSoil\tc5\tGlenCanyon\t5\tLane4\tN37_33.006\tW110_40.590\tSoil\tLocalSoilCrust\tsource\t3723\tNo\tNA\t37\tNA\t3732\t9\t9\t30\t2010\t14882\t1\tHCanyon10\tHcanyon\t3\t45\tGlenCanyon_hc9r3\n",
        "HCanyon11R1\tGTTCGCGTATAG\t11\thc10r1\t8.89\tSoil\te12\tGlenCanyon\t5\tLane4\tN37_33.002\tW110_40.585\tSoil\tLocalSoilCrust\tsource\t3733\tNo\tNA\t37\tNA\t3739\t6\t9\t30\t2010\t14882\t1\tHCanyon11\tHcanyon\t1\t109\tGlenCanyon_hc10r1\n",
        "HCanyon11R2\tTACGATGACCAC\t11\thc10r2\t8.84\tSoil\tf12\tGlenCanyon\t5\tLane4\tN37_33.002\tW110_40.585\tSoil\tLocalSoilCrust\tsource\t3733\tNo\tNA\t37\tNA\t3739\t6\t9\t30\t2010\t14882\t1\tHCanyon11\tHcanyon\t2\t110\tGlenCanyon_hc10r2\n",
        "HCanyon11R3\tTAGATAGCAGGA\t11\thc10r3\t8.9\tSoil\tg12\tGlenCanyon\t5\tLane4\tN37_33.002\tW110_40.585\tSoil\tLocalSoilCrust\tsource\t3733\tNo\tNA\t37\tNA\t3739\t6\t9\t30\t2010\t14882\t1\tHCanyon11\tHcanyon\t3\t111\tGlenCanyon_hc10r3\n",
        "HCanyon12R1\tGTAGCGCGAGTT\t12\thc11r1\t9.2\tSoil\tb11\tGlenCanyon\t5\tLane4\tN37_33.001\tW110_40.579\tSoil\tLocalSoilCrust\tsource\t3743\tNo\tNA\t37\tNA\t3749\t6\t9\t30\t2010\t14882\t1\tHCanyon12\tHcanyon\t1\t97\tGlenCanyon_hc11r1"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As you can tell, we're looking at a QIIME-compatible metadata mapping file. One thing we might want to do is read this file in, perform some processing, and process that information. Imagine for example that you want to know what pH range these soils cover - let's look at how to do that.\n",
      "\n",
      "First, we'll open the file for reading. Here I'm opening the file in ``U`` mode, to open with support for universal line breaks. This is how you should always open a file for reading, except in rare circumstances (specifically, if it's a binary file, like a ``.gz`` file - this is rare)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "f = open(fp,'U')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Often, we read files by iterating over the lines with a for loop. For example, we can do the following:\n",
      "\n",
      "``for line in f:``\n",
      "\n",
      "which will iteratively set line to each line in the file. In our case, we want to identify the first line in the file so we can find the ``sample_pH`` column index, and then we want to store that value for each line. We could do this as follows:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "pH = []\n",
      "for line in f:\n",
      "    # first, let's clean up the line by\n",
      "    # removing any leading or trailing \n",
      "    # whitespace\n",
      "    line = line.strip()\n",
      "    # then, let's split it into a list\n",
      "    # of tab-separated values\n",
      "    fields = line.split('\\t')\n",
      "    # next, let's check if the line is our \n",
      "    # header line\n",
      "    if line.startswith('#'):\n",
      "        # if so, then find the position of sample_pH \n",
      "        pH_index = fields.index('sample_pH')\n",
      "    else:\n",
      "        # if this isn't a header line, it\n",
      "        # must be a data line, so let's get the\n",
      "        # sample's pH\n",
      "        pH.append(float(fields[pH_index]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We should now have the all of the pH values. Let's check with a print statement."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print pH"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[9.52, 9.5, 9.29, 9.25, 9.23, 8.89, 8.84, 8.9, 9.2, 9.26, 9.29, 9.27, 9.21, 9.3, 9.27, 9.3, 9.3, 9.34, 9.21, 9.19, 9.1, 9.19, 9.2, 9.1, 8.16, 8.19, 8.2, 9.17, 9.15, 9.55, 9.44, 9.41, 8.02, 8.0, 8.05, 9.17, 9.16, 9.23, 9.26, 9.45, 9.41, 9.46, 9.49, 9.5, 9.54, 9.44, 9.42, 9.06, 9.01, 9.35, 9.4, 9.31, 9.26, 9.13, 9.55, 9.44, 9.41, 9.65, 9.71, 9.67, 9.49, 9.39, 9.42, 9.45, 9.49, 9.46, 9.47, 9.5, 9.51, 9.34, 9.3, 9.38, 8.89, 8.82, 8.9, 8.35, 8.3, 8.02, 8.0, 8.05, 8.13, 8.21, 8.44, 8.82, 8.75, 8.71, 8.85, 9.5, 9.54, 9.49, 9.29, 9.38, 9.35, 9.06, 8.9]"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are a few ways that we can check the min and max pH to determine the range. We'll go over these as a group to see what we come up with."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}